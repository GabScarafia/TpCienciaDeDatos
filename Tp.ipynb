{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28b70cae",
   "metadata": {},
   "source": [
    "# Notebook de Recomendaciones de Peliculas\n",
    "La idea es que a partir de un prompt del usuario se recomienden peliculas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98481415",
   "metadata": {},
   "source": [
    "## Imports y using\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53aad557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\gscarafia\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from -r requirements.txt (line 1)) (2.3.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\gscarafia\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from -r requirements.txt (line 2)) (1.7.0)\n",
      "Requirement already satisfied: sentence-transformers in c:\\users\\gscarafia\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from -r requirements.txt (line 3)) (4.1.0)\n",
      "Requirement already satisfied: faiss-cpu in c:\\users\\gscarafia\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from -r requirements.txt (line 4)) (1.11.0)\n",
      "Requirement already satisfied: wget in c:\\users\\gscarafia\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from -r requirements.txt (line 5)) (3.2)\n",
      "Requirement already satisfied: unzip in c:\\users\\gscarafia\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from -r requirements.txt (line 6)) (1.0.0)\n",
      "Collecting google-generativeai (from -r requirements.txt (line 8))\n",
      "  Using cached google_generativeai-0.8.5-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting spacy (from -r requirements.txt (line 9))\n",
      "  Using cached spacy-3.8.7-cp313-cp313-win_amd64.whl.metadata (28 kB)\n",
      "Collecting seaborn (from -r requirements.txt (line 10))\n",
      "  Using cached seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Ignored the following versions that require a different python version: 3.8.3 Requires-Python <3.13,>=3.9; 3.8.5 Requires-Python <3.13,>=3.9; 3.8.6 Requires-Python <3.13,>=3.9\n",
      "ERROR: Could not find a version that satisfies the requirement matplotlib.pyplot (from versions: none)\n",
      "ERROR: No matching distribution found for matplotlib.pyplot\n",
      "c:\\Users\\gscarafia\\AppData\\Local\\Programs\\Python\\Python313\\python.exe: No module named spacy\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'wordcloud'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m get_ipython().run_line_magic(\u001b[33m'\u001b[39m\u001b[33mpip\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33minstall -r requirements.txt\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      3\u001b[39m get_ipython().system(\u001b[33m'\u001b[39m\u001b[33mpython -m spacy download es_core_news_sm\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mwordcloud\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m WordCloud\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StandardScaler\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'wordcloud'"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt\n",
    "\n",
    "%python -m spacy download es_core_news_sm\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import os\n",
    "import wget\n",
    "import ast\n",
    "import google.generativeai as genai\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebe9378",
   "metadata": {},
   "source": [
    "## Gener√≥ Credenciales de Gemini "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d25c33f3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'genai' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m GEMINI_API_KEY = \u001b[33m\"\u001b[39m\u001b[33mAIzaSyB2lqerBn4B8VuHHg53v7mZF3kdGmE-i7k\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Configurar la API de Google Gemini\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[43mgenai\u001b[49m.configure(api_key=GEMINI_API_KEY)\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Listamos los modelos disponibles (lo usamos para debug)\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m genai.list_models():\n",
      "\u001b[31mNameError\u001b[39m: name 'genai' is not defined"
     ]
    }
   ],
   "source": [
    "# --- Configuraci√≥n de la API de Gemini ---\n",
    "GEMINI_API_KEY = \"AIzaSyB2lqerBn4B8VuHHg53v7mZF3kdGmE-i7k\"\n",
    "\n",
    "# Configurar la API de Google Gemini\n",
    "genai.configure(api_key=GEMINI_API_KEY)\n",
    "\n",
    "# Listamos los modelos disponibles (lo usamos para debug)\n",
    "for m in genai.list_models():\n",
    "    if \"generateContent\" in m.supported_generation_methods:\n",
    "        print(m.name)\n",
    "\n",
    "# Seleccionamos el modelo geminio que vamos a usar\n",
    "GEMINI_MODEL_NAME = \"gemini-2.0-flash\"\n",
    "\n",
    "try:\n",
    "    model = genai.GenerativeModel(GEMINI_MODEL_NAME)\n",
    "    print(f\"Modelo Gemini '{GEMINI_MODEL_NAME}' configurado exitosamente.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error al configurar el modelo Gemini: {e}\")\n",
    "    print(\"Por favor, verifica tu clave API y tu conexi√≥n a internet.\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e52a6c1",
   "metadata": {},
   "source": [
    "## Descarga de Dataset\n",
    "\n",
    "Se descarga de kaggle el movies-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08043ef2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m DATASET_CSV_NAME = \u001b[33m\"\u001b[39m\u001b[33mmovie_dataset.csv\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      5\u001b[39m DATASET_DIR = \u001b[33m\"\u001b[39m\u001b[33m./data/\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m DATASET_LOCAL_PATH = \u001b[43mos\u001b[49m.path.join(DATASET_DIR, DATASET_CSV_NAME)\n",
      "\u001b[31mNameError\u001b[39m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "# --- Configuraci√≥n del dataset de pel√≠culas ---\n",
    "DATASET_DOWNLOAD_URL = \"https://www.kaggle.com/api/v1/datasets/download/utkarshx27/movies-dataset\"\n",
    "DATASET_FILE_NAME = \"movies-dataset.zip\"\n",
    "DATASET_CSV_NAME = \"movie_dataset.csv\"\n",
    "DATASET_DIR = \"./data/\"\n",
    "DATASET_LOCAL_PATH = os.path.join(DATASET_DIR, DATASET_CSV_NAME)\n",
    "\n",
    "# Crea la carpeta de datos si no existe\n",
    "os.makedirs(DATASET_DIR, exist_ok=True)\n",
    "\n",
    "# Descarga el dataset si no existe localmente\n",
    "if not os.path.exists(DATASET_LOCAL_PATH):\n",
    "    print(f\"Descargando el dataset de pel√≠culas (aprox. 23 MB) a: {DATASET_DIR}\")\n",
    "    print(\"Esto puede tardar unos segundos...\")\n",
    "    try:\n",
    "        # wget descarga el zip, luego lo descomprimimos\n",
    "        zip_path = os.path.join(DATASET_DIR, DATASET_FILE_NAME)\n",
    "        wget.download(DATASET_DOWNLOAD_URL, out=zip_path)\n",
    "        print(\"\\nDescarga del ZIP completada. Descomprimiendo...\")\n",
    "\n",
    "        import zipfile\n",
    "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "            zip_ref.extract(DATASET_CSV_NAME, DATASET_DIR)\n",
    "        os.remove(zip_path) # Elimina el zip despu√©s de descomprimir\n",
    "        print(f\"Dataset '{DATASET_CSV_NAME}' descomprimido.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\nError al descargar o descomprimir el dataset: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d93481",
   "metadata": {},
   "source": [
    "## Preprocesamiento de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63294c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Preprocesamiento del dataset ---\n",
    "movies_df.rename(columns={'title': 'CleanTitle'}, inplace=True)\n",
    "\n",
    "movies_df.loc[:, 'Year'] = pd.to_datetime(movies_df['release_date'], errors='coerce').dt.year\n",
    "movies_df.loc[:, 'Year'] = movies_df['Year'].astype('Int64').fillna(0)\n",
    "movies_df.loc[movies_df['Year'] == 0, 'Year'] = 'a√±o desconocido'\n",
    "\n",
    "# --- Funciones de parsing ---\n",
    "def parse_genres_robust(genres_str):\n",
    "    if pd.isna(genres_str) or genres_str == '[]' or genres_str == '':\n",
    "        return []\n",
    "    try:\n",
    "        genres_list = ast.literal_eval(genres_str)\n",
    "        if isinstance(genres_list, list):\n",
    "            return [d['name'] for d in genres_list if isinstance(d, dict) and 'name' in d]\n",
    "        else:\n",
    "            raise ValueError(\"Not a list of dictionaries\")\n",
    "    except (ValueError, SyntaxError):\n",
    "        if ',' in genres_str:\n",
    "            return [g.strip() for g in genres_str.split(',') if g.strip()]\n",
    "        else:\n",
    "            return [g.strip() for g in genres_str.split(' ') if g.strip()]\n",
    "    except Exception as e:\n",
    "        print(f\"Advertencia al parsear g√©neros: {e}\")\n",
    "        return []\n",
    "\n",
    "def parse_cast_robust(cast_str):\n",
    "    if pd.isna(cast_str) or cast_str == '[]' or cast_str == '':\n",
    "        return []\n",
    "    try:\n",
    "        cast_list = ast.literal_eval(cast_str)\n",
    "        if isinstance(cast_list, list):\n",
    "            return [d['name'] for d in cast_list if isinstance(d, dict) and 'name' in d]\n",
    "        else:\n",
    "            raise ValueError(\"Not a list of dictionaries\")\n",
    "    except (ValueError, SyntaxError):\n",
    "        if ',' in cast_str:\n",
    "            return [c.strip() for c in cast_str.split(',') if c.strip()]\n",
    "        else:\n",
    "            return [cast_str.strip()]\n",
    "\n",
    "# Aplica funciones de parsing\n",
    "movies_df['genres_parsed'] = movies_df['genres'].apply(parse_genres_robust)\n",
    "\n",
    "# ‚úÖ Traducci√≥n de g√©neros del ingl√©s al espa√±ol\n",
    "genre_translation = {\n",
    "    \"Action\": \"Acci√≥n\",\n",
    "    \"Adventure\": \"Aventura\",\n",
    "    \"Comedy\": \"Comedia\",\n",
    "    \"Drama\": \"Drama\",\n",
    "    \"Science Fiction\": \"Ciencia Ficci√≥n\",\n",
    "    \"Science\": \"Ciencia\",\n",
    "    \"Fiction\": \"Ficci√≥n\",\n",
    "    \"Family\": \"Familiar\",\n",
    "    \"History\": \"Historia\",\n",
    "    \"Music\": \"Musical\",\n",
    "    \"Horror\": \"Terror\",\n",
    "    \"Thriller\": \"Thriller\",\n",
    "    \"Romance\": \"Romance\",\n",
    "    \"Animation\": \"Animaci√≥n\",\n",
    "    \"Documentary\": \"Documental\",\n",
    "    \"Mystery\": \"Misterio\",\n",
    "    \"Fantasy\": \"Fantas√≠a\",\n",
    "    \"Crime\": \"Crimen\",\n",
    "    \"War\": \"Guerra\",\n",
    "}\n",
    "\n",
    "def traducir_generos(generos):\n",
    "    return [genre_translation.get(g, g) for g in generos]\n",
    "\n",
    "movies_df['genres_traducidos'] = movies_df['genres_parsed'].apply(traducir_generos)\n",
    "movies_df['Genres'] = movies_df['genres_traducidos'].apply(lambda x: ', '.join(x) if x else '')\n",
    "\n",
    "# Cast\n",
    "movies_df['cast_parsed'] = movies_df['cast'].apply(parse_cast_robust)\n",
    "movies_df['CleanCast'] = movies_df['cast_parsed'].apply(lambda x: ', '.join(x) if x else '')\n",
    "\n",
    "# Promedio de rating\n",
    "movies_df.rename(columns={'vote_average': 'AvgRating'}, inplace=True)\n",
    "\n",
    "# Texto combinado para embeddings\n",
    "movies_df['combined_text'] = (\n",
    "    \"T√≠tulo: \" + movies_df['CleanTitle'].fillna('') + \". \" +\n",
    "    \"G√©neros: \" + movies_df['Genres'].fillna('') + \". \" +\n",
    "    \"Actores: \" + movies_df['CleanCast'].fillna('') + \". \" +\n",
    "    \"Sinopsis: \" + movies_df['overview'].fillna('')\n",
    ")\n",
    "\n",
    "# Elimina duplicados\n",
    "movies_df.drop_duplicates(subset=['CleanTitle', 'Year'], inplace=True, ignore_index=True)\n",
    "\n",
    "print(f\"Dataset preprocesado. Filas: {len(movies_df)}\")\n",
    "print(movies_df['combined_text'].sample(5).values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e8a5f6",
   "metadata": {},
   "source": [
    "## Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feac8c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos el modelo de embeddings\n",
    "#'paraphrase-multilingual-MiniLM-L12-v2' es poderoso para los multiples lenguajes\n",
    "print(\"Cargando modelo de embeddings (SentenceTransformer)...\")\n",
    "embedding_model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')\n",
    "print(\"Modelo de embeddings cargado.\")\n",
    "\n",
    "# Genera embeddings para el dataset preprocesado\n",
    "print(\"Generando embeddings para las pel√≠culas (esto puede tardar un poco)...\")\n",
    "movie_embeddings = embedding_model.encode(movies_df['combined_text'].tolist(), show_progress_bar=True)\n",
    "print(\"Embeddings generados.\")\n",
    "\n",
    "# Escala los embeddings\n",
    "scaler = StandardScaler()\n",
    "scaled_embeddings = scaler.fit_transform(movie_embeddings)\n",
    "\n",
    "# Crear el √≠ndice FAISS\n",
    "# D = dimensi√≥n de los embeddings (384 para all-MiniLM-L6-v2)\n",
    "D = scaled_embeddings.shape[1]\n",
    "index = faiss.IndexFlatL2(D) # L2 para distancia euclidiana (com√∫n para embeddings)\n",
    "index.add(scaled_embeddings)\n",
    "print(f\"√çndice FAISS creado con {index.ntotal} elementos.\")\n",
    "\n",
    "# Opcional: guardar/cargar el √≠ndice para no tener que regenerarlo\n",
    "# faiss.write_index(index, \"movie_embeddings.faiss\")\n",
    "# index = faiss.read_index(\"movie_embeddings.faiss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5c5389",
   "metadata": {},
   "source": [
    "## Nube de palabras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442c64f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "# Extraer todos los g√©neros individuales desde la columna 'genres_traducidos'\n",
    "todos_los_generos = [genero for sublist in movies_df['genres_traducidos'] for genero in sublist]\n",
    "\n",
    "# Contar frecuencias\n",
    "frecuencia_generos = Counter(todos_los_generos)\n",
    "\n",
    "# Crear la nube de palabras\n",
    "wordcloud = WordCloud(\n",
    "    width=800,\n",
    "    height=400,\n",
    "    background_color='white',\n",
    "    colormap='tab10'\n",
    ").generate_from_frequencies(frecuencia_generos)\n",
    "\n",
    "# Mostrarla\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.title('Frecuencia de G√©neros')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50285cf",
   "metadata": {},
   "source": [
    "## Procesamiento de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275489af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# Cargar el modelo de spaCy para espa√±ol\n",
    "nlp = spacy.load(\"es_core_news_sm\")\n",
    "\n",
    "# Lista de g√©neros en espa√±ol para detectar desde el prompt\n",
    "GENRES = [\n",
    "    \"acci√≥n\", \"aventura\", \"comedia\", \"drama\", \"ciencia ficci√≥n\", \"terror\", \"thriller\", \n",
    "    \"romance\", \"animaci√≥n\", \"documental\", \"misterio\", \"fantas√≠a\", \"crimen\"\n",
    "]\n",
    "\n",
    "# Extrae nombres de actores y g√©neros del prompt\n",
    "def extract_actor_and_genres(prompt):\n",
    "    doc = nlp(prompt)\n",
    "    actores = [ent.text for ent in doc.ents if ent.label_ == \"PER\"]  # spaCy reconoce nombres de personas\n",
    "\n",
    "    generos_encontrados = []\n",
    "    prompt_lower = prompt.lower()\n",
    "    for genero in GENRES:\n",
    "        if genero in prompt_lower:\n",
    "            generos_encontrados.append(genero.capitalize())  # Para coincidir con columna Genres\n",
    "\n",
    "    return actores, generos_encontrados\n",
    "\n",
    "\n",
    "import time\n",
    "\n",
    "def recommend_movies_mejorado(prompt, k=5):\n",
    "    actores, generos = extract_actor_and_genres(prompt)\n",
    "    df_filtrado = movies_df.copy()\n",
    "\n",
    "    if actores:\n",
    "        df_filtrado = df_filtrado[df_filtrado['CleanCast'].str.contains('|'.join(actores), case=False, na=False)]\n",
    "    if generos:\n",
    "        df_filtrado = df_filtrado[df_filtrado['Genres'].str.contains('|'.join(generos), case=False, na=False)]\n",
    "\n",
    "    if df_filtrado.empty:\n",
    "        df_filtrado = movies_df.copy()\n",
    "\n",
    "    # Filtrar los embeddings precalculados\n",
    "    indices_filtrados = df_filtrado.index.tolist()\n",
    "    filtered_embeddings = scaled_embeddings[indices_filtrados]\n",
    "\n",
    "    # Crear √≠ndice FAISS temporal con embeddings filtrados\n",
    "    D = filtered_embeddings.shape[1]\n",
    "    temp_index = faiss.IndexFlatL2(D)\n",
    "    temp_index.add(filtered_embeddings)\n",
    "\n",
    "    # Embedding del prompt\n",
    "    prompt_emb = embedding_model.encode([prompt])\n",
    "    scaled_prompt_emb = scaler.transform(prompt_emb)\n",
    "\n",
    "    distances, indices = temp_index.search(scaled_prompt_emb, k)\n",
    "    recomendadas = df_filtrado.iloc[indices[0]]\n",
    "\n",
    "    return recomendadas.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9731a9a",
   "metadata": {},
   "source": [
    "## llamado a Gemini "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42cac1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llamar_a_gemini(prompt_texto):\n",
    "    \"\"\"\n",
    "    Llama a la API de Google Gemini para generar una respuesta.\n",
    "    \"\"\"\n",
    "    model = genai.GenerativeModel(GEMINI_MODEL_NAME)\n",
    "\n",
    "\n",
    "    try:\n",
    "        response = model.generate_content(\n",
    "            prompt_texto,\n",
    "            generation_config=genai.types.GenerationConfig(\n",
    "                temperature=0.7,\n",
    "                max_output_tokens=500,\n",
    "            )\n",
    "        )\n",
    "        # El texto generado est√° en response.candidates[0].content.parts[0].text\n",
    "        return response.text\n",
    "    except Exception as e:\n",
    "        print(f\"Error al llamar a la API de Gemini: {e}\")\n",
    "        return \"Lo siento, no pude generar una recomendaci√≥n en este momento. Por favor, intenta de nuevo m√°s tarde.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f8c0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = input(\"¬øQu√© tipo de pel√≠cula quer√©s ver?: \")\n",
    "\n",
    "recommendations = recommend_movies_mejorado(user_prompt, k=5)\n",
    "\n",
    "resumen = \"\"\n",
    "for i, row in recommendations.iterrows():\n",
    "    movie_year = int(row['Year']) if pd.notna(row['Year']) and row['Year'] != 'a√±o desconocido' else 'a√±o desconocido'\n",
    "\n",
    "    resumen += (\n",
    "        f\"T√≠tulo: {row['CleanTitle']} ({movie_year}), \"\n",
    "        f\"G√©neros: {row['Genres']}, \"\n",
    "        f\"Actores: {row['CleanCast']}, \"\n",
    "        f\"Rating Promedio: {round(row['AvgRating'], 1)}.\\n\"\n",
    "        f\"Sinopsis: {row['overview']}\\n\\n\"\n",
    "    )\n",
    "prompt_llm = f\"\"\"\n",
    "Actu√° como un recomendador de pel√≠culas en espa√±ol. Un usuario te dijo lo siguiente:\n",
    "\"{user_prompt}\"\n",
    "\n",
    "Estas son tus opciones (con t√≠tulo, a√±o, g√©neros, actores, rating promedio y sinopsis):\n",
    "{resumen}\n",
    "\n",
    "Considerando la sinopsis, los g√©neros, los actores y el rating de las pel√≠culas, respond√© en tono natural y conversacional, recomendando las pel√≠culas que mejor se ajusten a la preferencia del usuario.\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\nGenerando recomendaci√≥n con Google Gemini (API)...\")\n",
    "respuesta = llamar_a_gemini(prompt_llm)\n",
    "print(\"\\nüé¨ Recomendaci√≥n personalizada:\\n\")\n",
    "print(respuesta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c66d0e7",
   "metadata": {},
   "source": [
    "## Visualizacion de Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15cb6580",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- An√°lisis de las caracter√≠sticas de las pel√≠culas recomendadas ---\")\n",
    "\n",
    "# Distribuci√≥n de G√©neros en las Recomendaciones\n",
    "print(\"\\nG√©neros m√°s comunes en las recomendaciones:\")\n",
    "# Aplanar la lista de g√©neros y contar ocurrencias\n",
    "all_genres = []\n",
    "for genres_str in recommendations['Genres']:\n",
    "    all_genres.extend([g.strip() for g in genres_str.split(',') if g.strip()])\n",
    "genre_counts = pd.Series(all_genres).value_counts().head(10)\n",
    "print(genre_counts)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=genre_counts.values, y=genre_counts.index, palette=\"viridis\")\n",
    "plt.title('Top 10 G√©neros en Pel√≠culas Recomendadas')\n",
    "plt.xlabel('N√∫mero de Pel√≠culas')\n",
    "plt.ylabel('G√©nero')\n",
    "plt.show()\n",
    "\n",
    "# Distribuci√≥n de Ratings Promedio en las Recomendaciones\n",
    "print(\"\\nDistribuci√≥n de Ratings Promedio en las recomendaciones:\")\n",
    "print(recommendations['AvgRating'].describe())\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(recommendations['AvgRating'], bins=5, kde=True)\n",
    "plt.title('Distribuci√≥n de Ratings Promedio de Pel√≠culas Recomendadas')\n",
    "plt.xlabel('Rating Promedio')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.show()\n",
    "\n",
    "# Distribuci√≥n de A√±os en las Recomendaciones\n",
    "print(\"\\nA√±os de lanzamiento de las pel√≠culas recomendadas:\")\n",
    "# Convertir 'a√±o desconocido' a NaN para la graficaci√≥n num√©rica, luego manejarlo por separado si es necesario\n",
    "years_for_plot = recommendations['Year'].apply(lambda x: np.nan if x == 'a√±o desconocido' else int(x))\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(years_for_plot.dropna(), bins=5, kde=False)\n",
    "plt.title('Distribuci√≥n de A√±os de Pel√≠culas Recomendadas')\n",
    "plt.xlabel('A√±o de Lanzamiento')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.show()\n",
    "if 'a√±o desconocido' in recommendations['Year'].values:\n",
    "    print(f\"Hay {sum(recommendations['Year'] == 'a√±o desconocido')} pel√≠cula(s) con a√±o desconocido en las recomendaciones.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
