{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2aba6e7f",
   "metadata": {},
   "source": [
    "Movie Recommendation Notebook\n",
    "-----------------------------\n",
    "This notebook lets you input a movie preference prompt (e.g., \"I want to watch a sci-fi romance with strong female leads\")\n",
    "and returns a top-5 list of recommended movies based on dataset embeddings and similarity search.\n",
    "\n",
    "# 1. Install and import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a937101e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Marina\\source\\repos\\TpCienciaDeDatos\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/gemini-1.0-pro-vision-latest\n",
      "models/gemini-pro-vision\n",
      "models/gemini-1.5-pro-latest\n",
      "models/gemini-1.5-pro-002\n",
      "models/gemini-1.5-pro\n",
      "models/gemini-1.5-flash-latest\n",
      "models/gemini-1.5-flash\n",
      "models/gemini-1.5-flash-002\n",
      "models/gemini-1.5-flash-8b\n",
      "models/gemini-1.5-flash-8b-001\n",
      "models/gemini-1.5-flash-8b-latest\n",
      "models/gemini-2.5-pro-preview-03-25\n",
      "models/gemini-2.5-flash-preview-04-17\n",
      "models/gemini-2.5-flash-preview-05-20\n",
      "models/gemini-2.5-flash\n",
      "models/gemini-2.5-flash-preview-04-17-thinking\n",
      "models/gemini-2.5-flash-lite-preview-06-17\n",
      "models/gemini-2.5-pro-preview-05-06\n",
      "models/gemini-2.5-pro-preview-06-05\n",
      "models/gemini-2.5-pro\n",
      "models/gemini-2.0-flash-exp\n",
      "models/gemini-2.0-flash\n",
      "models/gemini-2.0-flash-001\n",
      "models/gemini-2.0-flash-exp-image-generation\n",
      "models/gemini-2.0-flash-lite-001\n",
      "models/gemini-2.0-flash-lite\n",
      "models/gemini-2.0-flash-preview-image-generation\n",
      "models/gemini-2.0-flash-lite-preview-02-05\n",
      "models/gemini-2.0-flash-lite-preview\n",
      "models/gemini-2.0-pro-exp\n",
      "models/gemini-2.0-pro-exp-02-05\n",
      "models/gemini-exp-1206\n",
      "models/gemini-2.0-flash-thinking-exp-01-21\n",
      "models/gemini-2.0-flash-thinking-exp\n",
      "models/gemini-2.0-flash-thinking-exp-1219\n",
      "models/gemini-2.5-flash-preview-tts\n",
      "models/gemini-2.5-pro-preview-tts\n",
      "models/learnlm-2.0-flash-experimental\n",
      "models/gemma-3-1b-it\n",
      "models/gemma-3-4b-it\n",
      "models/gemma-3-12b-it\n",
      "models/gemma-3-27b-it\n",
      "models/gemma-3n-e4b-it\n",
      "models/gemma-3n-e2b-it\n",
      "Modelo Gemini 'gemini-2.0-flash' configurado exitosamente.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import os\n",
    "import wget\n",
    "import google.generativeai as genai\n",
    "\n",
    "# --- Configuración del dataset de películas ---\n",
    "DATASET_DOWNLOAD_URL = \"https://www.kaggle.com/api/v1/datasets/download/utkarshx27/movies-dataset\"\n",
    "DATASET_FILE_NAME = \"movies-dataset.zip\"\n",
    "DATASET_CSV_NAME = \"movie_dataset.csv\"\n",
    "DATASET_DIR = \"./data/\"\n",
    "DATASET_LOCAL_PATH = os.path.join(DATASET_DIR, DATASET_CSV_NAME)\n",
    "\n",
    "# --- Configuración de la API de Gemini ---\n",
    "GEMINI_API_KEY = \"AIzaSyDkt35etFDXRdrWfGC3mIttC17g9IxlZic\"\n",
    "\n",
    "# Configurar la API de Google Gemini\n",
    "genai.configure(api_key=GEMINI_API_KEY)\n",
    "\n",
    "# Listamos los modelos disponibles (lo usamos para debug)\n",
    "for m in genai.list_models():\n",
    "    if \"generateContent\" in m.supported_generation_methods:\n",
    "        print(m.name)\n",
    "\n",
    "# Seleccionamos el modelo geminio que vamos a usar\n",
    "GEMINI_MODEL_NAME = \"gemini-2.0-flash\"\n",
    "\n",
    "try:\n",
    "    model = genai.GenerativeModel(GEMINI_MODEL_NAME)\n",
    "    print(f\"Modelo Gemini '{GEMINI_MODEL_NAME}' configurado exitosamente.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error al configurar el modelo Gemini: {e}\")\n",
    "    print(\"Por favor, verifica tu clave API y tu conexión a internet.\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f89953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando el dataset desde: ./data/movie_dataset.csv\n",
      "Dataset cargado exitosamente.\n",
      "Index(['index', 'budget', 'genres', 'homepage', 'id', 'keywords',\n",
      "       'original_language', 'original_title', 'overview', 'popularity',\n",
      "       'production_companies', 'production_countries', 'release_date',\n",
      "       'revenue', 'runtime', 'spoken_languages', 'status', 'tagline', 'title',\n",
      "       'vote_average', 'vote_count', 'cast', 'crew', 'director'],\n",
      "      dtype='object')\n",
      "Dataset preprocesado. Filas: 4803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Marina\\AppData\\Local\\Temp\\ipykernel_8268\\2666931603.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'año desconocido' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  movies_df.loc[movies_df['Year'] == 0, 'Year'] = 'año desconocido' # Luego reemplazamos 0 por el string\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "\n",
    "# Crea la carpeta de datos si no existe\n",
    "os.makedirs(DATASET_DIR, exist_ok=True)\n",
    "\n",
    "# Descarga el dataset si no existe localmente\n",
    "if not os.path.exists(DATASET_LOCAL_PATH):\n",
    "    print(f\"Descargando el dataset de películas (aprox. 23 MB) a: {DATASET_DIR}\")\n",
    "    print(\"Esto puede tardar unos segundos...\")\n",
    "    try:\n",
    "        # wget descarga el zip, luego lo descomprimimos\n",
    "        zip_path = os.path.join(DATASET_DIR, DATASET_FILE_NAME)\n",
    "        wget.download(DATASET_DOWNLOAD_URL, out=zip_path)\n",
    "        print(\"\\nDescarga del ZIP completada. Descomprimiendo...\")\n",
    "\n",
    "        import zipfile\n",
    "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "            zip_ref.extract(DATASET_CSV_NAME, DATASET_DIR)\n",
    "        os.remove(zip_path) # Elimina el zip después de descomprimir\n",
    "        print(f\"Dataset '{DATASET_CSV_NAME}' descomprimido.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\nError al descargar o descomprimir el dataset: {e}\")\n",
    "        print(\"Por favor, verifica tu conexión a internet o la URL del dataset.\")\n",
    "        raise # Levanta el error para que el notebook se detenga\n",
    "\n",
    "print(f\"Cargando el dataset desde: {DATASET_LOCAL_PATH}\")\n",
    "movies_df = pd.read_csv(DATASET_LOCAL_PATH)\n",
    "print(\"Dataset cargado exitosamente.\")\n",
    "\n",
    "# Para debug: Mostramos las columnas del dataset para verificar su estructura\n",
    "print(movies_df.columns)\n",
    "\n",
    "# --- Preprocesamiento del dataset ---\n",
    "# Renombramos columnas para consistencia\n",
    "movies_df.rename(columns={'title': 'CleanTitle'}, inplace=True)\n",
    "\n",
    "# Extraemos el año de 'release_date'\n",
    "# Usamos .loc para evitar el SettingWithCopyWarning y asegurar la modificación directa\n",
    "movies_df.loc[:, 'Year'] = pd.to_datetime(movies_df['release_date'], errors='coerce').dt.year\n",
    "# Convertimos a Int64 para manejar NaNs como enteros o un tipo de entero que acepta nulos\n",
    "movies_df.loc[:, 'Year'] = movies_df['Year'].astype('Int64').fillna(0) # Temporalmente a 0 para mantener tipo numérico\n",
    "movies_df.loc[movies_df['Year'] == 0, 'Year'] = 'año desconocido' # Luego reemplazamos 0 por el string\n",
    "\n",
    "\n",
    "# Función para parsear los géneros\n",
    "def parse_genres_robust(genres_str):\n",
    "    if pd.isna(genres_str) or genres_str == '[]' or genres_str == '':\n",
    "        return []\n",
    "    try:\n",
    "        # Evalua como una lista de diccionarios (el formato más común)\n",
    "        genres_list = ast.literal_eval(genres_str)\n",
    "        if isinstance(genres_list, list):\n",
    "            return [d['name'] for d in genres_list if isinstance(d, dict) and 'name' in d]\n",
    "        else: # Si no es una lista, podría ser un string simple malformado\n",
    "            raise ValueError(\"Not a list of dictionaries\")\n",
    "    except (ValueError, SyntaxError):\n",
    "        # Si ast.literal_eval falla, intenta dividir por comas o espacios.\n",
    "        if ',' in genres_str:\n",
    "            return [g.strip() for g in genres_str.split(',') if g.strip()]\n",
    "        else: # Si no hay comas, intenta por espacios\n",
    "            return [g.strip() for g in genres_str.split(' ') if g.strip()]\n",
    "    except Exception as e:\n",
    "        print(f\"Advertencia: Error inesperado al parsear géneros '{genres_str}': {e}\")\n",
    "        return []\n",
    "\n",
    "# Aplica la función a la columna 'genres'\n",
    "movies_df.loc[:, 'genres_parsed'] = movies_df['genres'].apply(parse_genres_robust)\n",
    "movies_df.loc[:, 'Genres'] = movies_df['genres_parsed'].apply(lambda x: ', '.join(x) if x else '')\n",
    "\n",
    "# El 'vote_average' es el rating promedio global\n",
    "movies_df.rename(columns={'vote_average': 'AvgRating'}, inplace=True)\n",
    "\n",
    "movies_df['CleanCast'] = movies_df['cast'].fillna('')\n",
    "# Combina texto para embeddings (título, géneros, y SINOPIS/OVERVIEW)\n",
    "movies_df.loc[:, 'combined_text'] = movies_df['CleanTitle'].fillna('') + ' ' + \\\n",
    "                                     movies_df['Genres'].fillna('') + ' ' + \\\n",
    "                                     movies_df['CleanCast'].fillna('') + ' ' + \\\n",
    "                                     movies_df['overview'].fillna('')\n",
    "\n",
    "# Elimina duplicados si hay (basado en CleanTitle y Year)\n",
    "movies_df.drop_duplicates(subset=['CleanTitle', 'Year'], inplace=True, ignore_index=True)\n",
    "\n",
    "print(f\"Dataset preprocesado. Filas: {len(movies_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e47750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando modelo de embeddings (SentenceTransformer)...\n",
      "Modelo de embeddings cargado.\n",
      "Generando embeddings para las películas (esto puede tardar un poco)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches:  16%|█▌        | 24/151 [01:09<05:57,  2.82s/it]"
     ]
    }
   ],
   "source": [
    "# Cargamos el modelo de embeddings\n",
    "# 'all-MiniLM-L6-v2' es ligero y bueno para inglés.\n",
    "# (para mejor rendimineto en español usar 'paraphrase-multilingual-MiniLM-L12-v2' es más grande)\n",
    "print(\"Cargando modelo de embeddings (SentenceTransformer)...\")\n",
    "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "print(\"Modelo de embeddings cargado.\")\n",
    "\n",
    "# Genera embeddings para el dataset preprocesado\n",
    "print(\"Generando embeddings para las películas (esto puede tardar un poco)...\")\n",
    "movie_embeddings = embedding_model.encode(movies_df['combined_text'].tolist(), show_progress_bar=True)\n",
    "print(\"Embeddings generados.\")\n",
    "\n",
    "# Escala los embeddings\n",
    "scaler = StandardScaler()\n",
    "scaled_embeddings = scaler.fit_transform(movie_embeddings)\n",
    "\n",
    "# Crear el índice FAISS\n",
    "# D = dimensión de los embeddings (384 para all-MiniLM-L6-v2)\n",
    "D = scaled_embeddings.shape[1]\n",
    "index = faiss.IndexFlatL2(D) # L2 para distancia euclidiana (común para embeddings)\n",
    "index.add(scaled_embeddings)\n",
    "print(f\"Índice FAISS creado con {index.ntotal} elementos.\")\n",
    "\n",
    "# Opcional: guardar/cargar el índice para no tener que regenerarlo\n",
    "# faiss.write_index(index, \"movie_embeddings.faiss\")\n",
    "# index = faiss.read_index(\"movie_embeddings.faiss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e738593",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_movies(user_prompt, k=5):\n",
    "    \"\"\"\n",
    "    Recomienda películas basadas en un prompt del usuario,\n",
    "    usando embeddings del nuevo dataset y FAISS.\n",
    "    \"\"\"\n",
    "    # Genera embedding para el prompt del usuario\n",
    "    user_embedding = embedding_model.encode([user_prompt])\n",
    "    \n",
    "    # Escala el embedding del usuario\n",
    "    scaled_user_embedding = scaler.transform(user_embedding)\n",
    "    \n",
    "    # Realiza búsqueda de similitud en el índice FAISS\n",
    "    distances, indices = index.search(scaled_user_embedding, k)\n",
    "    \n",
    "    # Obtiene las películas recomendadas del DataFrame original\n",
    "    recommended_movies = movies_df.iloc[indices[0]]\n",
    "    \n",
    "    # Opcional: podemos añadir un filtro mínimo de 'vote_count'  para recomendaciones más robustas\n",
    "    \n",
    "    return recommended_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178b80d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302da52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llamar_a_gemini(prompt_texto):\n",
    "    \"\"\"\n",
    "    Llama a la API de Google Gemini para generar una respuesta.\n",
    "    \"\"\"\n",
    "    model = genai.GenerativeModel(GEMINI_MODEL_NAME)\n",
    "\n",
    "\n",
    "    try:\n",
    "        response = model.generate_content(\n",
    "            prompt_texto,\n",
    "            generation_config=genai.types.GenerationConfig(\n",
    "                temperature=0.7,\n",
    "                max_output_tokens=500,\n",
    "            )\n",
    "        )\n",
    "        # El texto generado está en response.candidates[0].content.parts[0].text\n",
    "        return response.text\n",
    "    except Exception as e:\n",
    "        print(f\"Error al llamar a la API de Gemini: {e}\")\n",
    "        return \"Lo siento, no pude generar una recomendación en este momento. Por favor, intenta de nuevo más tarde.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f914675b",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = input(\"¿Qué tipo de película querés ver?: \")\n",
    "\n",
    "recommendations = recommend_movies(user_prompt, k=5)\n",
    "\n",
    "resumen = \"\"\n",
    "for i, row in recommendations.iterrows():\n",
    "    movie_year = int(row['Year']) if pd.notna(row['Year']) and row['Year'] != 'año desconocido' else 'año desconocido'\n",
    "\n",
    "    resumen += (\n",
    "        f\"Título: {row['CleanTitle']} ({movie_year}), \"\n",
    "        f\"Géneros: {row['Genres']}, \"\n",
    "        f\"Actores: {row['CleanCast']}, \"\n",
    "        f\"Rating Promedio: {round(row['AvgRating'], 1)}.\\n\"\n",
    "        f\"Sinopsis: {row['overview']}\\n\\n\"\n",
    "    )\n",
    "\n",
    "prompt_llm = f\"\"\"\n",
    "Actuá como un recomendador de películas en español. Un usuario te dijo lo siguiente:\n",
    "\"{user_prompt}\"\n",
    "\n",
    "Estas son tus opciones (con título, año, géneros, actores, rating promedio y sinopsis):\n",
    "{resumen}\n",
    "\n",
    "Considerando la sinopsis, los géneros, los actores y el rating de las películas, respondé en tono natural y conversacional, recomendando las películas que mejor se ajusten a la preferencia del usuario.\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\nGenerando recomendación con Google Gemini (API)...\")\n",
    "respuesta = llamar_a_gemini(prompt_llm)\n",
    "print(\"\\n🎬 Recomendación personalizada:\\n\")\n",
    "print(respuesta)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
